# CS224n-study 3회

[👈 README.md로 되돌아가기](../README.md)

2019년 04월 21일 일요일에 진행한 CS224n 스터디 내용이며, 5강 ([Linguistic Structure: Dependency Parsing](http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture05-dep-parsing.pdf)), 6강([The probability of a sentence? Recurrent Neural Networks and Language Models](http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture06-rnnlm.pdf))을 공부한 내용입니다.

## 내용 정리

### 5강 정리

**자료 링크**

* [영민님 정리](https://baekyeongmin.github.io/cs224n/cs224n_lecture5/)
* [욱재님 정리](https://jeongukjae.github.io/posts/cs224n-lecture-5-dependency-parsing/)
* [진형님 정리](https://seo-jinbro.github.io/2019-04-21-cs224n-lecture-05/)

**질문**

* 진형님 질문: **Neural Parser** 에서 *POS*, *Dependency* 에 관한 feature 들을 Embedding 할 때 Dimension 이 어떻게 되나요? 어떤 식으로 처리하나요? -> *Word* 와 같은 차원으로 Embedding 하고, 강의에 나와있던 것처럼 해당 정보가 같으면 Embedding vector가 비슷하게 묶일 것. [A Fast and Accurate Dependency Parser using Neural Networks](https://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf) 을 참고.

* 욱재님 질문: **Non Projective** 한 경우는? (= Cross 될 경우는?) -> 이 부분은 추가로 찾아서 정리하는 것으로.

**참고 링크**

* Dependency Parser
  * https://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf

### 6강 정리

**자료 링크**

* [진형님 정리](https://seo-jinbro.github.io/2019-04-21-cs224n-lecture-06/)
* [욱재님 정리](https://jeongukjae.github.io/posts/cs224n-lecture-6-language-model-and-rnn/)

## 과제/이슈

Assignment 2 에서 image 뽑는 것 그렇게 오래 안걸리니 각자 해보는 것으로.

## 추후의 내용 정리

* 4/28, 5/5 은 스터디 없음
* 다음 스터디까지 7,8강 진행
* 과제는 3, 4까지 진행할 수 있으면 진행 (자율)
