# CS224n-study 3íšŒ

[ğŸ‘ˆ README.mdë¡œ ë˜ëŒì•„ê°€ê¸°](../README.md)

2019ë…„ 04ì›” 21ì¼ ì¼ìš”ì¼ì— ì§„í–‰í•œ CS224n ìŠ¤í„°ë”” ë‚´ìš©ì´ë©°, 5ê°• ([Linguistic Structure: Dependency Parsing](http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture05-dep-parsing.pdf)), 6ê°•([The probability of a sentence? Recurrent Neural Networks and Language Models](http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture06-rnnlm.pdf))ì„ ê³µë¶€í•œ ë‚´ìš©ì…ë‹ˆë‹¤.

## ë‚´ìš© ì •ë¦¬

### 5ê°• ì •ë¦¬

**ìë£Œ ë§í¬**

* [ì˜ë¯¼ë‹˜ ì •ë¦¬](https://baekyeongmin.github.io/cs224n/cs224n_lecture5/)
* [ìš±ì¬ë‹˜ ì •ë¦¬](https://jeongukjae.github.io/posts/cs224n-lecture-5-dependency-parsing/)
* [ì§„í˜•ë‹˜ ì •ë¦¬](https://seo-jinbro.github.io/2019-04-21-cs224n-lecture-05/)

**ì§ˆë¬¸**

* ì§„í˜•ë‹˜ ì§ˆë¬¸: **Neural Parser** ì—ì„œ *POS*, *Dependency* ì— ê´€í•œ feature ë“¤ì„ Embedding í•  ë•Œ Dimension ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”? ì–´ë–¤ ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ë‚˜ìš”? -> *Word* ì™€ ê°™ì€ ì°¨ì›ìœ¼ë¡œ Embedding í•˜ê³ , ê°•ì˜ì— ë‚˜ì™€ìˆë˜ ê²ƒì²˜ëŸ¼ í•´ë‹¹ ì •ë³´ê°€ ê°™ìœ¼ë©´ Embedding vectorê°€ ë¹„ìŠ·í•˜ê²Œ ë¬¶ì¼ ê²ƒ. [A Fast and Accurate Dependency Parser using Neural Networks](https://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf) ì„ ì°¸ê³ .

* ìš±ì¬ë‹˜ ì§ˆë¬¸: **Non Projective** í•œ ê²½ìš°ëŠ”? (= Cross ë  ê²½ìš°ëŠ”?) -> ì´ ë¶€ë¶„ì€ ì¶”ê°€ë¡œ ì°¾ì•„ì„œ ì •ë¦¬í•˜ëŠ” ê²ƒìœ¼ë¡œ.

**ì°¸ê³  ë§í¬**

* Dependency Parser
  * https://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf

### 6ê°• ì •ë¦¬

**ìë£Œ ë§í¬**

* [ì§„í˜•ë‹˜ ì •ë¦¬](https://seo-jinbro.github.io/2019-04-21-cs224n-lecture-06/)
* [ìš±ì¬ë‹˜ ì •ë¦¬](https://jeongukjae.github.io/posts/cs224n-lecture-6-language-model-and-rnn/)

## ê³¼ì œ/ì´ìŠˆ

Assignment 2 ì—ì„œ image ë½‘ëŠ” ê²ƒ ê·¸ë ‡ê²Œ ì˜¤ë˜ ì•ˆê±¸ë¦¬ë‹ˆ ê°ì í•´ë³´ëŠ” ê²ƒìœ¼ë¡œ.

## ì¶”í›„ì˜ ë‚´ìš© ì •ë¦¬

* 4/28, 5/5 ì€ ìŠ¤í„°ë”” ì—†ìŒ
* ë‹¤ìŒ ìŠ¤í„°ë””ê¹Œì§€ 7,8ê°• ì§„í–‰
* ê³¼ì œëŠ” 3, 4ê¹Œì§€ ì§„í–‰í•  ìˆ˜ ìˆìœ¼ë©´ ì§„í–‰ (ììœ¨)
